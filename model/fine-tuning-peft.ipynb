{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7724489,"sourceType":"datasetVersion","datasetId":4512622}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## install dependancies","metadata":{}},{"cell_type":"code","source":"# install Hugging Face Libraries\n!pip install peft\n!pip install transformers datasets accelerate evaluate bitsandbytes loralib --upgrade --quiet\n# install additional dependencies needed for training\n!pip install rouge-score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-03T00:46:51.415053Z","iopub.execute_input":"2024-03-03T00:46:51.415967Z","iopub.status.idle":"2024-03-03T00:48:01.417990Z","shell.execute_reply.started":"2024-03-03T00:46:51.415930Z","shell.execute_reply":"2024-03-03T00:48:01.417024Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting peft\n  Downloading peft-0.9.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.24.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.37.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.26.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.2)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.20.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.9.0-py3-none-any.whl (190 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.9.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.0 which is incompatible.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.0.11 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.0 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.24.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=4032b07ee7e99216c3f6d567e796ac74e94296c52ab9141c428a090262c0f6fb\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score\nSuccessfully installed rouge-score-0.1.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/full-data/train_data_full.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:48:01.420484Z","iopub.execute_input":"2024-03-03T00:48:01.421497Z","iopub.status.idle":"2024-03-03T00:48:03.292401Z","shell.execute_reply.started":"2024-03-03T00:48:01.421431Z","shell.execute_reply":"2024-03-03T00:48:03.291416Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                link  \\\n0  https://www.youtube.com/watch?v=9He4UBLyk8Y&li...   \n1  https://www.youtube.com/watch?v=1m8NRrLLgkg&li...   \n2  https://www.youtube.com/watch?v=8M3YqhO3kVs&li...   \n3  https://www.youtube.com/watch?v=VrSJhTGMM90&li...   \n4  https://www.youtube.com/watch?v=YY2ZhUQZyE4&li...   \n\n                                          transcript  transcript_length  \\\n0  in this video I'm going to explain all the cor...              11309   \n1  I would strongly recommend studying computer s...                791   \n2  have you ever noticed this little icon on your...                647   \n3  so what is python used for python is actually ...                522   \n4  are you a professional developer or someone wh...                556   \n\n  language                                            summary  \n0  English  This video provides a comprehensive overview o...  \n1  English  The video strongly recommends studying compute...  \n2  English  In the video, the speaker explains how to cust...  \n3  English  In this video, the main ideas discussed are th...  \n4  English  In this video, the speaker discusses the benef...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>link</th>\n      <th>transcript</th>\n      <th>transcript_length</th>\n      <th>language</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.youtube.com/watch?v=9He4UBLyk8Y&amp;li...</td>\n      <td>in this video I'm going to explain all the cor...</td>\n      <td>11309</td>\n      <td>English</td>\n      <td>This video provides a comprehensive overview o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.youtube.com/watch?v=1m8NRrLLgkg&amp;li...</td>\n      <td>I would strongly recommend studying computer s...</td>\n      <td>791</td>\n      <td>English</td>\n      <td>The video strongly recommends studying compute...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.youtube.com/watch?v=8M3YqhO3kVs&amp;li...</td>\n      <td>have you ever noticed this little icon on your...</td>\n      <td>647</td>\n      <td>English</td>\n      <td>In the video, the speaker explains how to cust...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://www.youtube.com/watch?v=VrSJhTGMM90&amp;li...</td>\n      <td>so what is python used for python is actually ...</td>\n      <td>522</td>\n      <td>English</td>\n      <td>In this video, the main ideas discussed are th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.youtube.com/watch?v=YY2ZhUQZyE4&amp;li...</td>\n      <td>are you a professional developer or someone wh...</td>\n      <td>556</td>\n      <td>English</td>\n      <td>In this video, the speaker discusses the benef...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# arabic video that had wrong english transcripts\ndf.drop(df.iloc[2600:2609].index , inplace = True)\ndf = df.reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:48:03.293938Z","iopub.execute_input":"2024-03-03T00:48:03.294330Z","iopub.status.idle":"2024-03-03T00:48:03.309263Z","shell.execute_reply.started":"2024-03-03T00:48:03.294296Z","shell.execute_reply":"2024-03-03T00:48:03.308488Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\nds = load_dataset(\"ccdv/cnn_dailymail\" , '3.0.0')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:48:03.311222Z","iopub.execute_input":"2024-03-03T00:48:03.311546Z","iopub.status.idle":"2024-03-03T00:52:21.864057Z","shell.execute_reply.started":"2024-03-03T00:48:03.311521Z","shell.execute_reply":"2024-03-03T00:52:21.862957Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for ccdv/cnn_dailymail contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/ccdv/cnn_dailymail\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/9.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"006c877d4a174b2a98278c3af7403c31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/13.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe4c83d182be4fcfb6532a8c0c7b2c28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/159M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a41c243a16474b18a1eabe7467cbab56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/376M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08c22da567874949b7d938b227df61ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/572k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fdc306a3d3c43e887d315a68b81d78e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/12.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5315ffe5d41422e9428715bac9e804f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/661k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75a48465c787486cba852b025bb3edc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"162883bfb90a49df950000c6703d654a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb2e79be63bb4dfd998db6a64a4d00e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4d35422583a477b81d7d261c6200cbf"}},"metadata":{}}]},{"cell_type":"code","source":"df = df.drop(['link' , 'transcript_length' , 'language'] , axis = 1).rename(columns = {'transcript': 'text'})\ndf","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:52:21.865297Z","iopub.execute_input":"2024-03-03T00:52:21.865711Z","iopub.status.idle":"2024-03-03T00:52:21.886721Z","shell.execute_reply.started":"2024-03-03T00:52:21.865671Z","shell.execute_reply":"2024-03-03T00:52:21.884620Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                   text  \\\n0     in this video I'm going to explain all the cor...   \n1     I would strongly recommend studying computer s...   \n2     have you ever noticed this little icon on your...   \n3     so what is python used for python is actually ...   \n4     are you a professional developer or someone wh...   \n...                                                 ...   \n7475  guys welcome back to the third video in my Pyt...   \n7476  guys so welcome to the second video in the ser...   \n7477  guys so welcome back today I'm going to be doi...   \n7478  there and welcome to the space shooter game th...   \n7479  in this tutorial we're going to create a layou...   \n\n                                                summary  \n0     This video provides a comprehensive overview o...  \n1     The video strongly recommends studying compute...  \n2     In the video, the speaker explains how to cust...  \n3     In this video, the main ideas discussed are th...  \n4     In this video, the speaker discusses the benef...  \n...                                                 ...  \n7475  In this video tutorial on Python programming, ...  \n7476  This video is the second in a series about Pyt...  \n7477  In this video, the presenter introduces viewer...  \n7478  In this video, the creator covers the final to...  \n7479  In this video tutorial, the main ideas discuss...  \n\n[7480 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>in this video I'm going to explain all the cor...</td>\n      <td>This video provides a comprehensive overview o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I would strongly recommend studying computer s...</td>\n      <td>The video strongly recommends studying compute...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>have you ever noticed this little icon on your...</td>\n      <td>In the video, the speaker explains how to cust...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>so what is python used for python is actually ...</td>\n      <td>In this video, the main ideas discussed are th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>are you a professional developer or someone wh...</td>\n      <td>In this video, the speaker discusses the benef...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7475</th>\n      <td>guys welcome back to the third video in my Pyt...</td>\n      <td>In this video tutorial on Python programming, ...</td>\n    </tr>\n    <tr>\n      <th>7476</th>\n      <td>guys so welcome to the second video in the ser...</td>\n      <td>This video is the second in a series about Pyt...</td>\n    </tr>\n    <tr>\n      <th>7477</th>\n      <td>guys so welcome back today I'm going to be doi...</td>\n      <td>In this video, the presenter introduces viewer...</td>\n    </tr>\n    <tr>\n      <th>7478</th>\n      <td>there and welcome to the space shooter game th...</td>\n      <td>In this video, the creator covers the final to...</td>\n    </tr>\n    <tr>\n      <th>7479</th>\n      <td>in this tutorial we're going to create a layou...</td>\n      <td>In this video tutorial, the main ideas discuss...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7480 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import random\nimport numpy as np\n\nrandom.seed(44)\n\nindices_to_remove = np.random.choice(df.index, 750, replace=False)\n\nval_df = df.loc[indices_to_remove]\n\ntrain_df = df.drop(indices_to_remove)\n\ntrain_df.shape , val_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:52:21.888613Z","iopub.execute_input":"2024-03-03T00:52:21.889009Z","iopub.status.idle":"2024-03-03T00:52:23.222143Z","shell.execute_reply.started":"2024-03-03T00:52:21.888960Z","shell.execute_reply":"2024-03-03T00:52:23.221107Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"((6730, 2), (750, 2))"},"metadata":{}}]},{"cell_type":"code","source":"train_ds = ds[\"train\"].select(random.sample(range(len(ds['train'])), 6000))\nval_ds = ds[\"validation\"].select(random.sample(range(len(ds['validation'])), 750))\ntrain_ds , val_ds","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:52:23.225245Z","iopub.execute_input":"2024-03-03T00:52:23.225616Z","iopub.status.idle":"2024-03-03T00:52:23.282741Z","shell.execute_reply.started":"2024-03-03T00:52:23.225588Z","shell.execute_reply":"2024-03-03T00:52:23.281742Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['article', 'highlights', 'id'],\n     num_rows: 6000\n }),\n Dataset({\n     features: ['article', 'highlights', 'id'],\n     num_rows: 750\n }))"},"metadata":{}}]},{"cell_type":"code","source":"train_ds = train_ds.remove_columns('id')\ntrain_ds = train_ds.rename_column('article' , 'text')\ntrain_ds = train_ds.rename_column('highlights' , 'summary')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:52:23.283769Z","iopub.execute_input":"2024-03-03T00:52:23.284040Z","iopub.status.idle":"2024-03-03T00:52:23.300439Z","shell.execute_reply.started":"2024-03-03T00:52:23.284016Z","shell.execute_reply":"2024-03-03T00:52:23.299584Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"val_ds = val_ds.remove_columns('id')\nval_ds = val_ds.rename_column('article' , 'text')\nval_ds = val_ds.rename_column('highlights' , 'summary')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:52:23.301789Z","iopub.execute_input":"2024-03-03T00:52:23.302618Z","iopub.status.idle":"2024-03-03T00:52:23.312114Z","shell.execute_reply.started":"2024-03-03T00:52:23.302583Z","shell.execute_reply":"2024-03-03T00:52:23.311428Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from datasets import DatasetDict , Dataset, concatenate_datasets\n\nds = DatasetDict({\n    'train': concatenate_datasets([train_ds , Dataset.from_pandas(train_df) ]),\n    'validation': concatenate_datasets([val_ds , Dataset.from_pandas(val_df) ])\n})\nds = ds.shuffle(seed = 42)\nds","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:52:23.313105Z","iopub.execute_input":"2024-03-03T00:52:23.313695Z","iopub.status.idle":"2024-03-03T00:52:23.854548Z","shell.execute_reply.started":"2024-03-03T00:52:23.313669Z","shell.execute_reply":"2024-03-03T00:52:23.853677Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'summary', '__index_level_0__'],\n        num_rows: 12730\n    })\n    validation: Dataset({\n        features: ['text', 'summary', '__index_level_0__'],\n        num_rows: 1500\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Convert text to text to token IDs","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nmodel_id=\"facebook/bart-base\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:52:23.856161Z","iopub.execute_input":"2024-03-03T00:52:23.856529Z","iopub.status.idle":"2024-03-03T00:52:31.111269Z","shell.execute_reply.started":"2024-03-03T00:52:23.856497Z","shell.execute_reply":"2024-03-03T00:52:31.110260Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e206784b9fd541709b4fe4f269f5eeae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f6b932e0e12483c8a35fb657e3e85aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af3df1ad0ff44f6b9a8149acf3052806"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b0b398b37af45e4a859655a24661233"}},"metadata":{}}]},{"cell_type":"code","source":"max_input_length = 1024\nmax_target_length = 500\n\n\ndef preprocess_function(examples):\n    model_inputs = tokenizer(\n        examples[\"text\"],\n        max_length=max_input_length,\n        truncation=True,\n    )\n    labels = tokenizer(\n        examples[\"summary\"], max_length=max_target_length, truncation=True\n    )\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_dataset = ds.map(preprocess_function, batched=True, remove_columns=ds['train'].column_names)\nprint(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:52:31.112866Z","iopub.execute_input":"2024-03-03T00:52:31.113354Z","iopub.status.idle":"2024-03-03T00:53:03.520167Z","shell.execute_reply.started":"2024-03-03T00:52:31.113325Z","shell.execute_reply":"2024-03-03T00:53:03.519224Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12730 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f07dbf6c1e74d13a961e5884ad0a833"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a47f200a336f409a8337122206493a01"}},"metadata":{}},{"name":"stdout","text":"Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Fine-Tune T5 with LoRA and bnb int-8","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\nimport torch\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_id)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:09:18.012204Z","iopub.execute_input":"2024-03-03T04:09:18.013117Z","iopub.status.idle":"2024-03-03T04:09:19.217800Z","shell.execute_reply.started":"2024-03-03T04:09:18.013079Z","shell.execute_reply":"2024-03-03T04:09:19.216638Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, TaskType\n\n# Define LoRA Config\nlora_config = LoraConfig(\n r = 8,\n lora_alpha = 16,\n target_modules=[\"q_proj\", \"v_proj\"],\n lora_dropout=0.05,\n bias=\"none\",\n task_type=TaskType.SEQ_2_SEQ_LM\n)\n\n\n# prepare int-8 model for training\nmodel = prepare_model_for_int8_training(model)\n\n# add LoRA adaptor\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:09:24.219006Z","iopub.execute_input":"2024-03-03T04:09:24.219382Z","iopub.status.idle":"2024-03-03T04:09:24.300032Z","shell.execute_reply.started":"2024-03-03T04:09:24.219351Z","shell.execute_reply":"2024-03-03T04:09:24.299135Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"trainable params: 442,368 || all params: 139,862,784 || trainable%: 0.3162871404018384\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:145: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:53:29.182660Z","iopub.execute_input":"2024-03-03T00:53:29.183038Z","iopub.status.idle":"2024-03-03T00:53:29.191625Z","shell.execute_reply.started":"2024-03-03T00:53:29.183010Z","shell.execute_reply":"2024-03-03T00:53:29.190683Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"PeftModelForSeq2SeqLM(\n  (base_model): LoraModel(\n    (model): BartForConditionalGeneration(\n      (model): BartModel(\n        (shared): Embedding(50265, 768, padding_idx=1)\n        (encoder): BartEncoder(\n          (embed_tokens): Embedding(50265, 768, padding_idx=1)\n          (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n          (layers): ModuleList(\n            (0-5): 6 x BartEncoderLayer(\n              (self_attn): BartSdpaAttention(\n                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=768, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=768, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                )\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=768, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=768, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                )\n                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n              )\n              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (activation_fn): GELUActivation()\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n          (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (decoder): BartDecoder(\n          (embed_tokens): Embedding(50265, 768, padding_idx=1)\n          (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n          (layers): ModuleList(\n            (0-5): 6 x BartDecoderLayer(\n              (self_attn): BartSdpaAttention(\n                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=768, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=768, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                )\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=768, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=768, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                )\n                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n              )\n              (activation_fn): GELUActivation()\n              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (encoder_attn): BartSdpaAttention(\n                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n                (v_proj): lora.Linear(\n                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=768, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=768, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                )\n                (q_proj): lora.Linear(\n                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=768, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=768, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                )\n                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n              )\n              (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n          (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer,model=model)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:09:30.239344Z","iopub.execute_input":"2024-03-03T04:09:30.240059Z","iopub.status.idle":"2024-03-03T04:09:30.247098Z","shell.execute_reply.started":"2024-03-03T04:09:30.240029Z","shell.execute_reply":"2024-03-03T04:09:30.245973Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token = \"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\")","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:53:52.221847Z","iopub.execute_input":"2024-03-03T00:53:52.222723Z","iopub.status.idle":"2024-03-03T00:53:52.360128Z","shell.execute_reply.started":"2024-03-03T00:53:52.222694Z","shell.execute_reply":"2024-03-03T00:53:52.359232Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n\noutput_dir=\"lora-bart-base-fine-tuned-youtube-cnn-2\"\n\nbatch_size = 12\nnum_train_epochs = 8\n# Show the training loss with every epoch\nlogging_steps = len(tokenized_dataset[\"train\"]) // batch_size\nmodel_name = model_id.split(\"/\")[-1]\n\nargs = Seq2SeqTrainingArguments(\n    output_dir=output_dir,\n    evaluation_strategy=\"epoch\",\n    learning_rate=1e-3,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=num_train_epochs,\n    predict_with_generate=True,\n    logging_steps=logging_steps,\n    gradient_accumulation_steps = 3,\n     warmup_steps=1000,  # Gradually increase learning rate for the first 1000 steps\n    lr_scheduler_type=\"linear\",  # Linearly decrease after warmup\n    push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:09:39.800794Z","iopub.execute_input":"2024-03-03T04:09:39.801627Z","iopub.status.idle":"2024-03-03T04:09:39.813025Z","shell.execute_reply.started":"2024-03-03T04:09:39.801597Z","shell.execute_reply":"2024-03-03T04:09:39.811908Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"!pip install nltk","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:54:09.998699Z","iopub.execute_input":"2024-03-03T00:54:09.999057Z","iopub.status.idle":"2024-03-03T00:54:22.362597Z","shell.execute_reply.started":"2024-03-03T00:54:09.999029Z","shell.execute_reply":"2024-03-03T00:54:22.361354Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nnltk.download(\"punkt\")","metadata":{"execution":{"iopub.status.busy":"2024-03-03T00:54:22.364749Z","iopub.execute_input":"2024-03-03T00:54:22.365082Z","iopub.status.idle":"2024-03-03T00:54:22.930471Z","shell.execute_reply.started":"2024-03-03T00:54:22.365053Z","shell.execute_reply":"2024-03-03T00:54:22.929518Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import evaluate\nrouge_score = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:09:44.923551Z","iopub.execute_input":"2024-03-03T04:09:44.923925Z","iopub.status.idle":"2024-03-03T04:09:45.541022Z","shell.execute_reply.started":"2024-03-03T04:09:44.923898Z","shell.execute_reply":"2024-03-03T04:09:45.539958Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import sent_tokenize\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    # Decode generated summaries into text\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    # Decode reference summaries into text\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    # ROUGE expects a newline after each sentence\n    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n    # Compute ROUGE scores\n    result = rouge_score.compute(\n        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n    )\n    # Extract the scores\n    result = {key: value * 100 for key, value in result.items()}\n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"execution":{"iopub.status.busy":"2024-03-03T02:20:26.034868Z","iopub.execute_input":"2024-03-03T02:20:26.035236Z","iopub.status.idle":"2024-03-03T02:20:26.045425Z","shell.execute_reply.started":"2024-03-03T02:20:26.035206Z","shell.execute_reply":"2024-03-03T02:20:26.044471Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model.to(device)\n\n# Create Trainer instance\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:09:49.711131Z","iopub.execute_input":"2024-03-03T04:09:49.711511Z","iopub.status.idle":"2024-03-03T04:09:49.995954Z","shell.execute_reply.started":"2024-03-03T04:09:49.711479Z","shell.execute_reply":"2024-03-03T04:09:49.994789Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"trainer.train() # wandb token: da537992f9e4b785775d4a7fba53b76a16283a34","metadata":{"execution":{"iopub.status.busy":"2024-03-03T04:09:59.694512Z","iopub.execute_input":"2024-03-03T04:09:59.694904Z","iopub.status.idle":"2024-03-03T06:44:57.223849Z","shell.execute_reply.started":"2024-03-03T04:09:59.694875Z","shell.execute_reply":"2024-03-03T06:44:57.222769Z"},"trusted":true},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2824' max='2824' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2824/2824 2:34:54, Epoch 7/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>No log</td>\n      <td>2.291288</td>\n      <td>21.208400</td>\n      <td>9.675900</td>\n      <td>17.123200</td>\n      <td>19.514800</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>2.158853</td>\n      <td>21.264500</td>\n      <td>10.098400</td>\n      <td>17.463200</td>\n      <td>19.662900</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.773200</td>\n      <td>2.068147</td>\n      <td>21.425100</td>\n      <td>10.618000</td>\n      <td>17.768300</td>\n      <td>19.905300</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.773200</td>\n      <td>2.045544</td>\n      <td>21.348400</td>\n      <td>10.627600</td>\n      <td>17.728900</td>\n      <td>19.825400</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.345200</td>\n      <td>2.019005</td>\n      <td>21.635600</td>\n      <td>10.885300</td>\n      <td>17.945100</td>\n      <td>20.118800</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2.345200</td>\n      <td>2.021565</td>\n      <td>21.533500</td>\n      <td>10.856700</td>\n      <td>17.895400</td>\n      <td>20.041700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nCheckpoint destination directory lora-bart-base-fine-tuned-youtube-cnn-2/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nCheckpoint destination directory lora-bart-base-fine-tuned-youtube-cnn-2/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nCheckpoint destination directory lora-bart-base-fine-tuned-youtube-cnn-2/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2824, training_loss=2.4891402809207905, metrics={'train_runtime': 9296.8191, 'train_samples_per_second': 10.954, 'train_steps_per_second': 0.304, 'total_flos': 6.225539789876429e+16, 'train_loss': 2.4891402809207905, 'epoch': 7.98})"},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\n# Clear CUDA memory\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T01:01:04.296585Z","iopub.execute_input":"2024-03-03T01:01:04.297321Z","iopub.status.idle":"2024-03-03T01:01:04.302694Z","shell.execute_reply.started":"2024-03-03T01:01:04.297288Z","shell.execute_reply":"2024-03-03T01:01:04.301716Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(output_dir)\ntokenizer = AutoTokenizer.from_pretrained(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T06:45:16.457770Z","iopub.execute_input":"2024-03-03T06:45:16.458850Z","iopub.status.idle":"2024-03-03T06:45:17.847608Z","shell.execute_reply.started":"2024-03-03T06:45:16.458808Z","shell.execute_reply":"2024-03-03T06:45:17.846498Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"input_text = '''\nToday I’m showcasing six cool tools that  convert code into architectural diagrams.\nWhether you’re a developer documenting  systems or a tech lead sharing knowledge,  \nI think you’ll see some awesome options here.\nFirst up is Diagrams - a Python library that  lets you draw cloud system architectures in  \ncode. It was created for rapidly prototyping  new designs without separate diagramming tools.\nRepresenting diagrams as code allows tracking  of diagram changes in version control systems.\nGo Diagrams\nThis \"diagram as code\" approach bridges  documentation with system implementation.\nDiagrams supports visualizing infrastructure  across major providers and stacks:\nAWS, Azure, GCP, Kubernetes, and more.\nIt can also model on-premise nodes, SaaS services,  and major programming frameworks and languages.\nThe extensive catalog of icons  and intuitive syntax accelerates  \ndiagram creation for modern tech stacks.\nIf you prefer Go, there is Go-Diagrams.  It’s the same idea as the python version,  \nbut let’s you write in Go.\nNext is Mermaid - it enables creating diagrams  and visualizations using text. As a JavaScript  \nMermaid\nlibrary, Mermaid uses Markdown-style text  definitions that feed into a renderer to  \nmodify complex diagrams. Their stated goal is to  help documentation keep pace with development.\nMermaid aims to solve \"doc-rot\"  - where diagramming and docs take  \nprecious developer time yet  still get outdated quickly.\nThis ruins productivity and  organizational learning.\nMermaid enables even non-programmers to create  detailed visuals through the Mermaid Live Editor.\nIf you want an even more powerful  diagramming tool, check out PlantUML.\nPlan URL\nIt offers a domain-specific language to  generate many diagram types: sequence  \ndiagrams, architectural diagrams, network  topology, Gantt charts, and even ASCII art.\nPlantUML’s language is very capable but  has a bit more learning curve compared  \nto other tools we covered. The broad  features make PlantUML a flexible,  \npowerful option for embedding  diagrams alongside code.\nSQEditors\nThe next category of tools goes in the  opposite direction - ASCII diagram editors.\nThese tools allow you to draw diagrams visually  or in text and then render them as ASCII art. They  \nharness the power and simplicity of plain  text, which has been around for decades.\nASCII editors let you easily author  text-based diagrams, layouts, flow charts,  \nand more. Since they output in plain text  format, these diagrams can embed anywhere.\nMarkMap\nSome examples of this class  of tools include web-based  \nasciiflow and Monodraw, which is Mac only.\nFinally, Markmap creates and visualizes mind  maps derived from Markdown documents. It  \nparses Markdown content and extracts  its inherent hierarchies to render  \na mindmap. It’s great for connecting ideas  and their relationships defined in writing.\nIt supports various platforms but may not  work well on very large or complex mind maps.\nif you like our videos, you might like  our System Design Newsletter as well.\nIt covers topics in trends  and large-scale system design.\nTrusted by 500,000 readers.\nSubscribe it at blog.bytebytego.com.\n'''","metadata":{"execution":{"iopub.status.busy":"2024-03-03T06:51:57.041088Z","iopub.execute_input":"2024-03-03T06:51:57.041778Z","iopub.status.idle":"2024-03-03T06:51:57.050525Z","shell.execute_reply.started":"2024-03-03T06:51:57.041748Z","shell.execute_reply":"2024-03-03T06:51:57.049502Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"model_input = tokenizer(input_text , truncation = False, return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2024-03-03T06:53:05.227972Z","iopub.execute_input":"2024-03-03T06:53:05.228335Z","iopub.status.idle":"2024-03-03T06:53:05.238177Z","shell.execute_reply.started":"2024-03-03T06:53:05.228305Z","shell.execute_reply":"2024-03-03T06:53:05.237282Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"summary_ids = model.generate(**model_input , max_length=400, min_length=50, do_sample = True, length_penalty=2.0, num_beams=4, top_k=50, top_p=0.95, temperature=0.8)\nsummary_ids","metadata":{"execution":{"iopub.status.busy":"2024-03-03T06:55:53.378846Z","iopub.execute_input":"2024-03-03T06:55:53.379236Z","iopub.status.idle":"2024-03-03T06:56:05.363756Z","shell.execute_reply.started":"2024-03-03T06:55:53.379206Z","shell.execute_reply":"2024-03-03T06:56:05.361834Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"tensor([[    2,     0,  1121,    42,   569,     6,     5, 14847, 22848,   411,\n          3035,  3270,    14, 10304,  3260,    88, 19481, 41882,     4,   252,\n           680,  3643, 17654,    29,   111,    10, 31886,  5560,    14,  8382,\n            47,  2451,  3613,   467, 41885,    11,  1437,  1437,  1437, 48619,\n            12, 20414,     4,    85,    21,  1412,    13,  6042, 40004,   154,\n          1437,    92,  7191,   396,  2559, 41071,  7059,  3270,     4,   152,\n          1548, 11879, 14877,    19,   467,  5574,     6,     8,    24,  4548,\n          7133,  2787,  2112,   420,   538,  4898,     8, 32201,   101, 26177,\n             6, 25959,     6,   272,  7496,     6,  9609,  1943,  4135,   293,\n             6,     8,    55,     4,    20, 14847,    67, 19197,     5,  2568,\n          5149,  7438, 21794,     6,    61,  4865,  7614,    11,  3926,     8,\n           739,    12,  8056,   467,  1521,     4,     2]])"},"metadata":{}}]},{"cell_type":"code","source":"summary_ids.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-03T06:56:05.365995Z","iopub.execute_input":"2024-03-03T06:56:05.366361Z","iopub.status.idle":"2024-03-03T06:56:05.375335Z","shell.execute_reply.started":"2024-03-03T06:56:05.366327Z","shell.execute_reply":"2024-03-03T06:56:05.374206Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 117])"},"metadata":{}}]},{"cell_type":"code","source":"summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T06:56:05.376423Z","iopub.execute_input":"2024-03-03T06:56:05.376744Z","iopub.status.idle":"2024-03-03T06:56:05.382343Z","shell.execute_reply.started":"2024-03-03T06:56:05.376720Z","shell.execute_reply":"2024-03-03T06:56:05.381272Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"summary_text","metadata":{"execution":{"iopub.status.busy":"2024-03-03T06:56:05.384617Z","iopub.execute_input":"2024-03-03T06:56:05.384957Z","iopub.status.idle":"2024-03-03T06:56:05.393524Z","shell.execute_reply.started":"2024-03-03T06:56:05.384926Z","shell.execute_reply":"2024-03-03T06:56:05.392571Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"'In this video, the presenter showcases six cool tools that convert code into architectural diagrams. They include Diagrams - a Python library that lets you draw cloud system architectures in   GUI-code. It was created for rapidly prototyping  new designs without separate diagramming tools. This approach bridges documentation with system implementation, and it supports visualizing infrastructure across major providers and stacks like AWS, Azure, GCP, Kubernetes, and more. The presenter also mentions the upcoming System Design Newsletter, which covers topics in trends and large-scale system design.'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install lsg-converter","metadata":{"execution":{"iopub.status.busy":"2024-03-03T06:46:39.625794Z","iopub.execute_input":"2024-03-03T06:46:39.626686Z","iopub.status.idle":"2024-03-03T06:46:53.258495Z","shell.execute_reply.started":"2024-03-03T06:46:39.626651Z","shell.execute_reply":"2024-03-03T06:46:53.257316Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting lsg-converter\n  Downloading lsg_converter-0.1.9-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: transformers>=4.36.1 in /opt/conda/lib/python3.10/site-packages (from lsg-converter) (4.38.2)\nRequirement already satisfied: torch>=1.8 in /opt/conda/lib/python3.10/site-packages (from lsg-converter) (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8->lsg-converter) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8->lsg-converter) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8->lsg-converter) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8->lsg-converter) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8->lsg-converter) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8->lsg-converter) (2023.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.36.1->lsg-converter) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.36.1->lsg-converter) (1.24.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.36.1->lsg-converter) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.36.1->lsg-converter) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.36.1->lsg-converter) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.36.1->lsg-converter) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.36.1->lsg-converter) (0.15.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.36.1->lsg-converter) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.36.1->lsg-converter) (4.66.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.36.1->lsg-converter) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8->lsg-converter) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.36.1->lsg-converter) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.36.1->lsg-converter) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.36.1->lsg-converter) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.36.1->lsg-converter) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8->lsg-converter) (1.3.0)\nDownloading lsg_converter-0.1.9-py3-none-any.whl (129 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: lsg-converter\nSuccessfully installed lsg-converter-0.1.9\n","output_type":"stream"}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-03-03T06:47:45.786501Z","iopub.execute_input":"2024-03-03T06:47:45.786908Z","iopub.status.idle":"2024-03-03T06:47:45.801940Z","shell.execute_reply.started":"2024-03-03T06:47:45.786873Z","shell.execute_reply":"2024-03-03T06:47:45.800877Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"BartForConditionalGeneration(\n  (model): BartModel(\n    (shared): Embedding(50265, 768, padding_idx=1)\n    (encoder): BartEncoder(\n      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n      (layers): ModuleList(\n        (0-5): 6 x BartEncoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): lora.Linear(\n              (base_layer): Linear(in_features=768, out_features=768, bias=True)\n              (lora_dropout): ModuleDict(\n                (default): Dropout(p=0.05, inplace=False)\n              )\n              (lora_A): ModuleDict(\n                (default): Linear(in_features=768, out_features=8, bias=False)\n              )\n              (lora_B): ModuleDict(\n                (default): Linear(in_features=8, out_features=768, bias=False)\n              )\n              (lora_embedding_A): ParameterDict()\n              (lora_embedding_B): ParameterDict()\n            )\n            (q_proj): lora.Linear(\n              (base_layer): Linear(in_features=768, out_features=768, bias=True)\n              (lora_dropout): ModuleDict(\n                (default): Dropout(p=0.05, inplace=False)\n              )\n              (lora_A): ModuleDict(\n                (default): Linear(in_features=768, out_features=8, bias=False)\n              )\n              (lora_B): ModuleDict(\n                (default): Linear(in_features=8, out_features=768, bias=False)\n              )\n              (lora_embedding_A): ParameterDict()\n              (lora_embedding_B): ParameterDict()\n            )\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n      (layers): ModuleList(\n        (0-5): 6 x BartDecoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): lora.Linear(\n              (base_layer): Linear(in_features=768, out_features=768, bias=True)\n              (lora_dropout): ModuleDict(\n                (default): Dropout(p=0.05, inplace=False)\n              )\n              (lora_A): ModuleDict(\n                (default): Linear(in_features=768, out_features=8, bias=False)\n              )\n              (lora_B): ModuleDict(\n                (default): Linear(in_features=8, out_features=768, bias=False)\n              )\n              (lora_embedding_A): ParameterDict()\n              (lora_embedding_B): ParameterDict()\n            )\n            (q_proj): lora.Linear(\n              (base_layer): Linear(in_features=768, out_features=768, bias=True)\n              (lora_dropout): ModuleDict(\n                (default): Dropout(p=0.05, inplace=False)\n              )\n              (lora_A): ModuleDict(\n                (default): Linear(in_features=768, out_features=8, bias=False)\n              )\n              (lora_B): ModuleDict(\n                (default): Linear(in_features=8, out_features=768, bias=False)\n              )\n              (lora_embedding_A): ParameterDict()\n              (lora_embedding_B): ParameterDict()\n            )\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n            (v_proj): lora.Linear(\n              (base_layer): Linear(in_features=768, out_features=768, bias=True)\n              (lora_dropout): ModuleDict(\n                (default): Dropout(p=0.05, inplace=False)\n              )\n              (lora_A): ModuleDict(\n                (default): Linear(in_features=768, out_features=8, bias=False)\n              )\n              (lora_B): ModuleDict(\n                (default): Linear(in_features=8, out_features=768, bias=False)\n              )\n              (lora_embedding_A): ParameterDict()\n              (lora_embedding_B): ParameterDict()\n            )\n            (q_proj): lora.Linear(\n              (base_layer): Linear(in_features=768, out_features=768, bias=True)\n              (lora_dropout): ModuleDict(\n                (default): Dropout(p=0.05, inplace=False)\n              )\n              (lora_A): ModuleDict(\n                (default): Linear(in_features=768, out_features=8, bias=False)\n              )\n              (lora_B): ModuleDict(\n                (default): Linear(in_features=8, out_features=768, bias=False)\n              )\n              (lora_embedding_A): ParameterDict()\n              (lora_embedding_B): ParameterDict()\n            )\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"from lsg_converter import LSGConverter\n\nconverter = LSGConverter(max_sequence_length=4096)\n\n# Example 1\nmodel, tokenizer = converter.convert_from_pretrained(output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T06:49:32.777674Z","iopub.execute_input":"2024-03-03T06:49:32.778378Z","iopub.status.idle":"2024-03-03T06:49:32.924021Z","shell.execute_reply.started":"2024-03-03T06:49:32.778348Z","shell.execute_reply":"2024-03-03T06:49:32.922512Z"},"trusted":true},"execution_count":61,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[61], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m converter \u001b[38;5;241m=\u001b[39m LSGConverter(max_sequence_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4096\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Example 1\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(model))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lsg_converter/converter.py:73\u001b[0m, in \u001b[0;36mLSGConverter.convert_from_pretrained\u001b[0;34m(self, model_name_or_path, architecture, use_auth_token, **model_kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_from_pretrained\u001b[39m(\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     62\u001b[0m     model_name_or_path, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs\n\u001b[1;32m     66\u001b[0m     ):\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    mode_name_or_path (str): path to the model to convert\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    architecture (str): specific architecture (optional)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    model_kwargs: additional model args\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     model_type \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmodel_type\n\u001b[1;32m     76\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(model_kwargs, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1111\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1109\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1111\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1113\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py:633\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    635\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py:688\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME)\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 688\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:369\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(resolved_file):\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[0;32m--> 369\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Checkout \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         )\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mOSError\u001b[0m: lora-bart-base-fine-tuned-youtube-cnn-2 does not appear to have a file named config.json. Checkout 'https://huggingface.co/lora-bart-base-fine-tuned-youtube-cnn-2/None' for available files."],"ename":"OSError","evalue":"lora-bart-base-fine-tuned-youtube-cnn-2 does not appear to have a file named config.json. Checkout 'https://huggingface.co/lora-bart-base-fine-tuned-youtube-cnn-2/None' for available files.","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}